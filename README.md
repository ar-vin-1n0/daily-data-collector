# Daily Data Collector ğŸ•’ğŸ“Š

A Python automation project that periodically collects data from a public API, cleans it, and stores structured output.  
The project is fully config-driven, logged, and runs automatically using a scheduler.

---

## ğŸš€ Features

- API data collection using `requests`
- Config-driven architecture (no hardcoded values)
- Data cleaning using `pandas`
- CSV-based data storage
- Centralized logging
- Time-based scheduling (minutely / hourly / daily)
- Safe and repeatable pipeline execution

---

## ğŸ“ Project Structure

    project/
    â”œâ”€â”€ main.py               # Entry point & scheduler
    â”œâ”€â”€ data_collector.py     # API data collection logic
    â”œâ”€â”€ data_cleaner.py       # Data cleaning logic
    â”œâ”€â”€ config/
    â”‚   â””â”€â”€ config.json       # Central configuration
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ raw.csv           # Raw collected data
    â”‚   â””â”€â”€ output.csv        # Cleaned data
    â”œâ”€â”€ logs/
    â”‚   â””â”€â”€ app.log           # Application logs
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ README.md
â–¶ï¸ How It Works

Loads configuration from config.json

Sends an HTTP request to the configured API

Validates the response

Saves raw data to CSV

Cleans the data (removes empty rows / duplicates)

Saves cleaned data to output CSV

Logs each step

Repeats automatically based on schedule

â–¶ï¸ How to Run
1ï¸âƒ£ Install dependencies
pip install -r requirements.txt

2ï¸âƒ£ Start the automation
python main.py


The pipeline will now run automatically according to the configured schedule.

ğŸ“ Logging

Logs are written to the file defined in the config:

logs/app.log


Each run records:

Pipeline start and completion

Collection status

Cleaning status

Errors (if any)

ğŸ§  Design Notes

The pipeline is idempotent: each run creates a fresh snapshot of data.

The scheduler controls when the pipeline runs, not what data is returned.

The project is designed to be easily extended to:

Database storage

Historical data tracking

Multiple data sources

âœ… Status

This project demonstrates a complete, real-world Python automation workflow and serves as a strong foundation for advanced automation and data engineering tasks.


---
